{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "232b4df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bdfc69416b40288c9e0e357447adc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading CSV files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files loaded and merged.\n",
      "Calculating technical indicators (EMA, ATR, Rolling Averages)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e194a6d538cb4f449430bdce7d3a9fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Pairs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical indicators calculated.\n",
      "Starting backtest...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3728c0a4134b149f1e453deb45186d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtesting Pairs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Timeframe for GBP/USD:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for D1:   0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for H1:   0%|          | 0/17523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for H4:   0%|          | 0/4388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for M1:   0%|          | 0/1119040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for M30:   0%|          | 0/35036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for M5:   0%|          | 0/210033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Timeframe for EUR/USD:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for D1:   0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for H1:   0%|          | 0/17522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for H4:   0%|          | 0/4388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for M1:   0%|          | 0/1119244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for M30:   0%|          | 0/35035 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Rows for M5:   0%|          | 0/210026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trades: 62271\n",
      "Winning trades: 37554\n",
      "Losing trades: 24717\n",
      "Results saved to C:/Users/yaman/OneDrive/سطح المكتب/project1/strategys/Big Char Trada/output_folder\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ======== SETTINGS ========\n",
    "data_folder = r\"C:/Users/yaman/OneDrive/سطح المكتب/project1/strategys/Big Char Trada\"\n",
    "output_folder = os.path.join(data_folder, \"C:/Users/yaman/OneDrive/سطح المكتب/project1/strategys/Big Char Trada/output_folder\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Strategy parameters\n",
    "atr_period = 14\n",
    "tp_atr_factor = 1.5\n",
    "sl_atr_factor = 1.0\n",
    "ema_period = 50\n",
    "big_candle_factor = 1.5\n",
    "volume_factor = 1.5\n",
    "\n",
    "primary_pair = \"GBP/USD\"\n",
    "secondary_pair = \"EUR/USD\"\n",
    "\n",
    "timeframe_hierarchy = {\n",
    "    'M1': 'M5',\n",
    "    'M5': 'M15',\n",
    "    'M15': 'M30',\n",
    "    'M30': 'H1',\n",
    "    'H1': 'H4',\n",
    "    'H4': 'D1'\n",
    "}\n",
    "\n",
    "# ======== LOAD ALL CSV FILES ========\n",
    "all_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "data_list = []\n",
    "\n",
    "print(\"Loading CSV files...\")\n",
    "for file in tqdm(all_files, desc=\"Loading CSV files\"):\n",
    "    filename = os.path.basename(file).upper()\n",
    "    \n",
    "    # Determine encoding\n",
    "    if \"GBPUSD\" in filename:\n",
    "        encoding = \"utf-16\"\n",
    "        sep = ','  # Change to ';' if columns are semicolon separated\n",
    "    else:\n",
    "        encoding = \"utf-8-sig\"\n",
    "        sep = ','\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding=encoding, sep=sep)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Ensure datetime column\n",
    "    if 'DateTime' not in df.columns:\n",
    "        df.rename(columns={df.columns[0]: 'DateTime'}, inplace=True)\n",
    "    \n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'], errors='coerce')\n",
    "\n",
    "    # Assign currency pair\n",
    "    if \"EURUSD\" in filename:\n",
    "        df['Pair'] = \"EUR/USD\"\n",
    "    elif \"GBPUSD\" in filename:\n",
    "        df['Pair'] = \"GBP/USD\"\n",
    "    else:\n",
    "        df['Pair'] = \"Other\"\n",
    "    \n",
    "    # Assign timeframe\n",
    "    for tf in [\"M1\",\"M5\",\"M15\",\"M30\",\"H1\",\"H4\",\"D1\"]:\n",
    "        if tf in filename:\n",
    "            df['Timeframe'] = tf\n",
    "            break\n",
    "    else:\n",
    "        df['Timeframe'] = \"Other\"\n",
    "    \n",
    "    data_list.append(df)\n",
    "\n",
    "# Merge all data\n",
    "data = pd.concat(data_list, ignore_index=True)\n",
    "data.sort_values(['Pair','Timeframe','DateTime'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(\"CSV files loaded and merged.\")\n",
    "\n",
    "# ======== FUNCTIONS ========\n",
    "def calculate_atr(df, period):\n",
    "    \"\"\"Calculate ATR using exponential moving average\"\"\"\n",
    "    df['High_Low'] = df['High'] - df['Low']\n",
    "    df['High_PrevClose'] = abs(df['High'] - df['Close'].shift(1))\n",
    "    df['Low_PrevClose'] = abs(df['Low'] - df['Close'].shift(1))\n",
    "    df['True_Range'] = df[['High_Low', 'High_PrevClose', 'Low_PrevClose']].max(axis=1)\n",
    "    df['ATR'] = df['True_Range'].ewm(span=period, adjust=False).mean()\n",
    "    df.drop(columns=['High_Low', 'High_PrevClose', 'Low_PrevClose', 'True_Range'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def check_hit(open_price, high, low, close_price, direction, tp_price, sl_price):\n",
    "    \"\"\"Check if trade hit TP or SL\"\"\"\n",
    "    if direction == 1:  # Buy\n",
    "        if open_price >= tp_price: \n",
    "            return (\"Win\", tp_price)\n",
    "        if open_price <= sl_price: \n",
    "            return (\"Loss\", sl_price)\n",
    "    else:  # Sell\n",
    "        if open_price <= tp_price: \n",
    "            return (\"Win\", tp_price)\n",
    "        if open_price >= sl_price: \n",
    "            return (\"Loss\", sl_price)\n",
    "\n",
    "    if direction == 1:\n",
    "        if low <= sl_price <= high and low <= tp_price <= high:\n",
    "            return (\"Loss\", sl_price) if sl_price < tp_price else (\"Win\", tp_price) \n",
    "        elif high >= tp_price:\n",
    "            return (\"Win\", tp_price)\n",
    "        elif low <= sl_price:\n",
    "            return (\"Loss\", sl_price)\n",
    "        else:\n",
    "            return (None, None)\n",
    "    else:\n",
    "        if low <= tp_price <= high and low <= sl_price <= high:\n",
    "            return (\"Win\", tp_price) if tp_price < sl_price else (\"Loss\", sl_price)\n",
    "        elif low <= tp_price:\n",
    "            return (\"Win\", tp_price)\n",
    "        elif high >= sl_price:\n",
    "            return (\"Loss\", sl_price)\n",
    "        else:\n",
    "            return (None, None)\n",
    "\n",
    "# ======== PREPARE DATA ========\n",
    "processed_data_frames = []\n",
    "print(\"Calculating technical indicators (EMA, ATR, Rolling Averages)...\")\n",
    "for pair in tqdm(data['Pair'].unique(), desc=\"Processing Pairs\"):\n",
    "    df_pair = data[data['Pair']==pair].copy()\n",
    "    for tf in df_pair['Timeframe'].unique():\n",
    "        df = df_pair[df_pair['Timeframe']==tf].copy()\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df['EMA'] = df['Close'].ewm(span=ema_period, adjust=False).mean()\n",
    "        df = calculate_atr(df, atr_period)\n",
    "        df['CandleSize'] = df['Close'] - df['Open']\n",
    "        df['Rolling_Avg_CandleSize'] = df['CandleSize'].abs().rolling(window=ema_period, min_periods=1).mean()\n",
    "        if 'Volume' in df.columns:\n",
    "            df['Rolling_Avg_Volume'] = df['Volume'].rolling(window=ema_period, min_periods=1).mean()\n",
    "        processed_data_frames.append(df)\n",
    "\n",
    "data_processed = pd.concat(processed_data_frames, ignore_index=True)\n",
    "data_processed.sort_values(['Pair','Timeframe','DateTime'], inplace=True)\n",
    "data_processed.reset_index(drop=True, inplace=True)\n",
    "print(\"Technical indicators calculated.\")\n",
    "\n",
    "df_primary_all_tfs = data_processed[data_processed['Pair']==primary_pair].copy()\n",
    "\n",
    "# ======== BACKTEST ========\n",
    "trades = []\n",
    "df_by_tf = { (p, tf): data_processed[(data_processed['Pair']==p) & (data_processed['Timeframe']==tf)].copy()\n",
    "             for p in data_processed['Pair'].unique() for tf in data_processed['Timeframe'].unique() }\n",
    "\n",
    "print(\"Starting backtest...\")\n",
    "for pair in tqdm([primary_pair, secondary_pair], desc=\"Backtesting Pairs\"):\n",
    "    df_pair_all_tfs = data_processed[data_processed['Pair']==pair].copy()\n",
    "    \n",
    "    for tf in tqdm(df_pair_all_tfs['Timeframe'].unique(), desc=f\"  Timeframe for {pair}\", leave=False):\n",
    "        df = df_by_tf.get((pair, tf))\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "        \n",
    "        for i in tqdm(range(1, len(df)), desc=f\"    Rows for {tf}\", leave=False):\n",
    "            row = df.iloc[i]\n",
    "            prev = df.iloc[i-1]\n",
    "\n",
    "            if abs(prev['CandleSize']) < prev['Rolling_Avg_CandleSize'] * big_candle_factor:\n",
    "                continue\n",
    "\n",
    "            direction = 1 if prev['CandleSize'] > 0 else -1\n",
    "\n",
    "            # Higher timeframe check\n",
    "            higher_tf_to_check = timeframe_hierarchy.get(tf, None)\n",
    "            if higher_tf_to_check:\n",
    "                df_higher = df_by_tf.get((pair, higher_tf_to_check))\n",
    "                if df_higher is not None and not df_higher.empty:\n",
    "                    df_higher_subset = df_higher[df_higher['DateTime'] <= row['DateTime']]\n",
    "                    if not df_higher_subset.empty:\n",
    "                        row_higher = df_higher_subset.iloc[-1]\n",
    "                        if direction == 1 and row_higher['Close'] < row_higher['EMA']:\n",
    "                            continue\n",
    "                        if direction == -1 and row_higher['Close'] > row_higher['EMA']:\n",
    "                            continue\n",
    "\n",
    "            # Volume check\n",
    "            if 'Volume' in row.index and 'Rolling_Avg_Volume' in row.index and not pd.isna(row['Rolling_Avg_Volume']):\n",
    "                if row['Volume'] < row['Rolling_Avg_Volume'] * volume_factor:\n",
    "                    continue\n",
    "\n",
    "            # Secondary pair alignment with primary\n",
    "            if pair == secondary_pair and 'Primary_CandleSize' in row.index:\n",
    "                primary_direction = 1 if row['Primary_CandleSize'] > 0 else -1\n",
    "                if direction != primary_direction:\n",
    "                    continue\n",
    "\n",
    "            # Entry, TP, SL\n",
    "            entry_price = row['Open']\n",
    "            if not pd.isna(row['ATR']):\n",
    "                tp_price = entry_price + direction * (row['ATR'] * tp_atr_factor)\n",
    "                sl_price = entry_price - direction * (row['ATR'] * sl_atr_factor)\n",
    "            else:\n",
    "                tp_price = entry_price + direction * 0.0004\n",
    "                sl_price = entry_price - direction * 0.0002\n",
    "\n",
    "            result, exit_price = check_hit(entry_price, row['High'], row['Low'], row['Close'], direction, tp_price, sl_price)\n",
    "            if result is None:\n",
    "                result = \"Win\" if direction * (row['Close'] - entry_price) > 0 else \"Loss\"\n",
    "                exit_price = row['Close']\n",
    "\n",
    "            trades.append({\n",
    "                'Pair': pair,\n",
    "                'Timeframe': tf,\n",
    "                'EntryDateTime': row['DateTime'],\n",
    "                'EntryPrice': entry_price,\n",
    "                'TP': tp_price,\n",
    "                'SL': sl_price,\n",
    "                'ExitPrice': exit_price,\n",
    "                'Result': result,\n",
    "                'ATR_at_Entry': row['ATR'] if not pd.isna(row['ATR']) else None\n",
    "            })\n",
    "\n",
    "# ======== SAVE RESULTS ========\n",
    "trades_df = pd.DataFrame(trades)\n",
    "total_trades = len(trades_df)\n",
    "wins = trades_df[trades_df['Result']==\"Win\"]\n",
    "losses = trades_df[trades_df['Result']==\"Loss\"]\n",
    "\n",
    "print(f\"\\nTotal trades: {total_trades}\")\n",
    "print(f\"Winning trades: {len(wins)}\")\n",
    "print(f\"Losing trades: {len(losses)}\")\n",
    "\n",
    "# Save to CSV\n",
    "trades_df.to_csv(os.path.join(output_folder,\"all_trades.csv\"), index=False)\n",
    "wins.to_csv(os.path.join(output_folder,\"winning_trades.csv\"), index=False)\n",
    "losses.to_csv(os.path.join(output_folder,\"losing_trades.csv\"), index=False)\n",
    "print(f\"Results saved to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b28c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
