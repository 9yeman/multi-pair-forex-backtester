{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32843218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157077087d1a41f3aa428e776f8ba4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading CSV files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files loaded and merged.\n",
      "Calculating technical indicators (EMA, ATR, Rolling Averages)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f82df3cf7042d0ae4f62ad023c552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Pairs and Timeframes:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical indicators calculated.\n",
      "Starting backtest...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587ccde6755542fdbc2efe73555b70fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtesting Progress:   0%|          | 0/2773713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Peak Profit Duration for winning trades...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4354ae7c87b34054b97c9d3cbd0703de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Peak Profit:   0%|          | 0/32294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Profit Duration calculation complete.\n",
      "\n",
      "Total trades: 48174\n",
      "Winning trades: 32294\n",
      "Losing trades: 15880\n",
      "Results saved to C:/Users/yaman/OneDrive/سطح المكتب/project1/strategys/Big Char Trada/out\n",
      "\n",
      "Backtest complete with enhanced output files!\n",
      "All Trades (first 5 rows):\n",
      "   TradeID     Pair Timeframe Direction EntryDateTime  EntryPrice  \\\n",
      "0        1  EUR/USD        D1      Sell    2023-12-18     1.08968   \n",
      "1        2  EUR/USD        D1       Buy    2023-12-22     1.10101   \n",
      "2        3  EUR/USD        D1       Buy    2025-03-04     1.04854   \n",
      "3        4  EUR/USD        D1       Buy    2025-03-05     1.06192   \n",
      "4        5  EUR/USD        D1      Sell    2025-04-07     1.08890   \n",
      "\n",
      "   CandleSize_at_Entry  RollingAvgCandleSize_at_Entry  Volume_at_Entry  \\\n",
      "0             -0.00979                       0.004032           176756   \n",
      "1              0.00716                       0.004067           198705   \n",
      "2              0.00826                       0.003804            86576   \n",
      "3              0.01392                       0.004035            95542   \n",
      "4             -0.00876                       0.004565           156044   \n",
      "\n",
      "   RollingAvgVolume_at_Entry  ...  MaxFavorableExcursion  \\\n",
      "0                   65142.52  ...                0.00050   \n",
      "1                   74524.58  ...                0.00304   \n",
      "2                   45041.18  ...                0.01415   \n",
      "3                   46478.10  ...                0.01777   \n",
      "4                   62364.86  ...                0.00112   \n",
      "\n",
      "   HigherTimeframeToMonitor  HigherTimeframeClose  HigherTimeframeEMA  \\\n",
      "0                      None                   NaN                 NaN   \n",
      "1                      None                   NaN                 NaN   \n",
      "2                      None                   NaN                 NaN   \n",
      "3                      None                   NaN                 NaN   \n",
      "4                      None                   NaN                 NaN   \n",
      "\n",
      "   HigherTimeframeConditionMet  VolumeConditionMet PrimaryPairDirection  \\\n",
      "0                         True                True                 Sell   \n",
      "1                         True                True                  Buy   \n",
      "2                         True                True                  Buy   \n",
      "3                         True                True                  Buy   \n",
      "4                         True                True                 Sell   \n",
      "\n",
      "   PrimaryPairAlignment PeakProfitDurationInCandles  PeakProfitPrice  \n",
      "0                  True                         NaN              NaN  \n",
      "1                  True                         4.0          1.11396  \n",
      "2                  True                         3.0          1.08887  \n",
      "3                  True                         2.0          1.08887  \n",
      "4                  True                         NaN              NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "\n",
      "Winning Trades (first 5 rows):\n",
      "   TradeID     Pair Timeframe Direction EntryDateTime  EntryPrice  \\\n",
      "1        2  EUR/USD        D1       Buy    2023-12-22     1.10101   \n",
      "2        3  EUR/USD        D1       Buy    2025-03-04     1.04854   \n",
      "3        4  EUR/USD        D1       Buy    2025-03-05     1.06192   \n",
      "5        6  EUR/USD        D1       Buy    2025-04-11     1.11978   \n",
      "6        7  EUR/USD        D1       Buy    2025-04-14     1.13103   \n",
      "\n",
      "   CandleSize_at_Entry  RollingAvgCandleSize_at_Entry  Volume_at_Entry  \\\n",
      "1              0.00716                       0.004067           198705   \n",
      "2              0.00826                       0.003804            86576   \n",
      "3              0.01392                       0.004035            95542   \n",
      "5              0.02492                       0.005005           151045   \n",
      "6              0.01612                       0.005294           110580   \n",
      "\n",
      "   RollingAvgVolume_at_Entry  ...  MaxFavorableExcursion  \\\n",
      "1                   74524.58  ...                0.00304   \n",
      "2                   45041.18  ...                0.01415   \n",
      "3                   46478.10  ...                0.01777   \n",
      "5                   70302.90  ...                0.02758   \n",
      "6                   71142.96  ...                0.01139   \n",
      "\n",
      "   HigherTimeframeToMonitor  HigherTimeframeClose  HigherTimeframeEMA  \\\n",
      "1                      None                   NaN                 NaN   \n",
      "2                      None                   NaN                 NaN   \n",
      "3                      None                   NaN                 NaN   \n",
      "5                      None                   NaN                 NaN   \n",
      "6                      None                   NaN                 NaN   \n",
      "\n",
      "   HigherTimeframeConditionMet  VolumeConditionMet PrimaryPairDirection  \\\n",
      "1                         True                True                  Buy   \n",
      "2                         True                True                  Buy   \n",
      "3                         True                True                  Buy   \n",
      "5                         True                True                  Buy   \n",
      "6                         True                True                  Buy   \n",
      "\n",
      "   PrimaryPairAlignment PeakProfitDurationInCandles  PeakProfitPrice  \n",
      "1                  True                         4.0         1.113960  \n",
      "2                  True                         3.0         1.088870  \n",
      "3                  True                         2.0         1.088870  \n",
      "5                  True                         0.0         1.146077  \n",
      "6                  True                         2.0         1.141230  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re # Import regex for advanced filename parsing\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ======== SETTINGS ========\n",
    "# Ensure these paths are correct\n",
    "data_folder = r\"C:/Users/yaman/OneDrive/سطح المكتب/project1/strategys/Big Char Trada\" # Corrected: Added closing double quote here\n",
    "output_folder = os.path.join(data_folder, \"C:/Users/yaman/OneDrive/سطح المكتب/project1/strategys/Big Char Trada/out\") # Output folder created inside data_folder for better organization\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Strategy parameters\n",
    "atr_period = 14\n",
    "tp_atr_factor = 1.5\n",
    "sl_atr_factor = 1.0\n",
    "ema_period = 50\n",
    "big_candle_factor = 1.5\n",
    "volume_factor = 1.5\n",
    "\n",
    "primary_pair = \"GBP/USD\"\n",
    "secondary_pair = \"EUR/USD\"\n",
    "\n",
    "timeframe_hierarchy = {\n",
    "    'M1': 'M5',\n",
    "    'M5': 'M15',\n",
    "    'M15': 'M30',\n",
    "    'M30': 'H1',\n",
    "    'H1': 'H4',\n",
    "    'H4': 'D1'\n",
    "}\n",
    "\n",
    "# ======== LOAD ALL CSV FILES ========\n",
    "all_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "data_list = []\n",
    "\n",
    "print(\"Loading CSV files...\")\n",
    "for file in tqdm(all_files, desc=\"Loading CSV files\"):\n",
    "    filename = os.path.basename(file).upper()\n",
    "    \n",
    "    # Determine encoding and separator based on filename\n",
    "    encoding = \"utf-8-sig\" # Default to utf-8-sig\n",
    "    sep = ','\n",
    "\n",
    "    if \"GBPUSD\" in filename: # Assuming GBPUSD files might use UTF-16\n",
    "        encoding = \"utf-16\"\n",
    "        sep = ',' \n",
    "    elif \"EURUSD\" in filename: # Assuming EURUSD files might use UTF-8\n",
    "        encoding = \"utf-8-sig\"\n",
    "        sep = ','\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding=encoding, sep=sep)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename} with encoding {encoding} and sep '{sep}': {e}\")\n",
    "        # Try a different encoding if the first one fails\n",
    "        if encoding == \"utf-16\":\n",
    "            try:\n",
    "                df = pd.read_csv(file, encoding=\"utf-8-sig\", sep=sep)\n",
    "                print(f\"Successfully read {filename} with utf-8-sig after utf-16 failed.\")\n",
    "            except Exception as e2:\n",
    "                print(f\"Error reading {filename} with utf-8-sig also: {e2}. Skipping file.\")\n",
    "                continue\n",
    "        elif encoding == \"utf-8-sig\":\n",
    "            try:\n",
    "                df = pd.read_csv(file, encoding=\"utf-16\", sep=sep)\n",
    "                print(f\"Successfully read {filename} with utf-16 after utf-8-sig failed.\")\n",
    "            except Exception as e2:\n",
    "                print(f\"Error reading {filename} with utf-16 also: {e2}. Skipping file.\")\n",
    "                continue\n",
    "        else:\n",
    "            continue # Skip file if it can't be read with either encoding\n",
    "\n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Ensure datetime column exists and is parsed correctly\n",
    "    if 'DateTime' not in df.columns:\n",
    "        # Look for a column likely to be DateTime\n",
    "        potential_dt_cols = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "        if potential_dt_cols:\n",
    "            df.rename(columns={potential_dt_cols[0]: 'DateTime'}, inplace=True)\n",
    "        else:\n",
    "            # If no obvious column name, assume the first column is DateTime\n",
    "            df.rename(columns={df.columns[0]: 'DateTime'}, inplace=True)\n",
    "            \n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'], errors='coerce')\n",
    "    df.dropna(subset=['DateTime'], inplace=True) # Drop rows where DateTime parsing failed\n",
    "\n",
    "    # Assign currency pair\n",
    "    if \"EURUSD\" in filename:\n",
    "        df['Pair'] = \"EUR/USD\"\n",
    "    elif \"GBPUSD\" in filename:\n",
    "        df['Pair'] = \"GBP/USD\"\n",
    "    else:\n",
    "        # Try to infer pair from filename (e.g., \"XYZ_M5.csv\" -> \"XYZ\")\n",
    "        pair_match = re.search(r'([A-Z]{3}[A-Z]{3})', filename)\n",
    "        if pair_match:\n",
    "            df['Pair'] = pair_match.group(1)[:3] + \"/\" + pair_match.group(1)[3:]\n",
    "        else:\n",
    "            df['Pair'] = \"Other\" # If no known pair found\n",
    "\n",
    "    # Assign timeframe\n",
    "    for tf in [\"M1\",\"M5\",\"M15\",\"M30\",\"H1\",\"H4\",\"D1\"]:\n",
    "        if tf in filename:\n",
    "            df['Timeframe'] = tf\n",
    "            break\n",
    "    else:\n",
    "        df['Timeframe'] = \"Other\"\n",
    "    \n",
    "    data_list.append(df)\n",
    "\n",
    "# Merge all data\n",
    "data = pd.concat(data_list, ignore_index=True)\n",
    "data.sort_values(['Pair','Timeframe','DateTime'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(\"CSV files loaded and merged.\")\n",
    "\n",
    "# ======== FUNCTIONS ========\n",
    "def calculate_atr(df, period):\n",
    "    \"\"\"Calculate ATR using exponential moving average\"\"\"\n",
    "    df['High_Low'] = df['High'] - df['Low']\n",
    "    df['High_PrevClose'] = abs(df['High'] - df['Close'].shift(1))\n",
    "    df['Low_PrevClose'] = abs(df['Low'] - df['Close'].shift(1))\n",
    "    df['True_Range'] = df[['High_Low', 'High_PrevClose', 'Low_PrevClose']].max(axis=1)\n",
    "    df['ATR'] = df['True_Range'].ewm(span=period, adjust=False).mean()\n",
    "    df.drop(columns=['High_Low', 'High_PrevClose', 'Low_PrevClose', 'True_Range'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def check_hit(open_price, high, low, close_price, direction, tp_price, sl_price):\n",
    "    \"\"\"\n",
    "    Check if trade hit TP or SL within the current candle's range.\n",
    "    Also estimates MaxAdverseExcursion (MAE) and MaxFavorableExcursion (MFE) for the current candle.\n",
    "    Returns (result, exit_price, mae, mfe).\n",
    "    Note: This is a simplified MAE/MFE for a single candle. For multi-candle trades,\n",
    "    MAE/MFE would need to be tracked cumulatively.\n",
    "    \"\"\"\n",
    "    mae = 0.0 # Max Adverse Excursion (absolute value)\n",
    "    mfe = 0.0 # Max Favorable Excursion (absolute value)\n",
    "\n",
    "    if direction == 1:  # Buy Trade\n",
    "        # Immediate hits at open\n",
    "        if open_price >= tp_price: \n",
    "            return (\"Win\", tp_price, 0.0, tp_price - open_price)\n",
    "        if open_price <= sl_price: \n",
    "            return (\"Loss\", sl_price, open_price - sl_price, 0.0)\n",
    "\n",
    "        # Movement within the candle\n",
    "        if high >= tp_price and low <= sl_price: # Both TP and SL hit within candle\n",
    "            # Assume SL is hit first if both are reached, unless TP is closer to open\n",
    "            if (tp_price - open_price) < (open_price - sl_price): # TP is closer\n",
    "                result = \"Win\"\n",
    "                exit_p = tp_price\n",
    "            else: # SL is closer or equal distance\n",
    "                result = \"Loss\"\n",
    "                exit_p = sl_price\n",
    "            mae = open_price - low # Max adverse during candle\n",
    "            mfe = high - open_price # Max favorable during candle\n",
    "            return (result, exit_p, mae, mfe)\n",
    "        elif high >= tp_price: # Only TP hit\n",
    "            mae = open_price - low\n",
    "            mfe = high - open_price\n",
    "            return (\"Win\", tp_price, mae, mfe)\n",
    "        elif low <= sl_price: # Only SL hit\n",
    "            mae = open_price - low\n",
    "            mfe = high - open_price\n",
    "            return (\"Loss\", sl_price, mae, mfe)\n",
    "        else: # Neither hit, assume close price is exit\n",
    "            mae = open_price - low\n",
    "            mfe = high - open_price\n",
    "            return (None, None, mae, mfe)\n",
    "    \n",
    "    else:  # Sell Trade (direction == -1)\n",
    "        # Immediate hits at open\n",
    "        if open_price <= tp_price: \n",
    "            return (\"Win\", tp_price, 0.0, open_price - tp_price)\n",
    "        if open_price >= sl_price: \n",
    "            return (\"Loss\", sl_price, sl_price - open_price, 0.0)\n",
    "\n",
    "        # Movement within the candle\n",
    "        if low <= tp_price and high >= sl_price: # Both TP and SL hit within candle\n",
    "            # Assume SL is hit first if both are reached, unless TP is closer to open\n",
    "            if (open_price - tp_price) < (sl_price - open_price): # TP is closer\n",
    "                result = \"Win\"\n",
    "                exit_p = tp_price\n",
    "            else: # SL is closer or equal distance\n",
    "                result = \"Loss\"\n",
    "                exit_p = sl_price\n",
    "            mae = high - open_price\n",
    "            mfe = open_price - low\n",
    "            return (result, exit_p, mae, mfe)\n",
    "        elif low <= tp_price: # Only TP hit\n",
    "            mae = high - open_price\n",
    "            mfe = open_price - low\n",
    "            return (\"Win\", tp_price, mae, mfe)\n",
    "        elif high >= sl_price: # Only SL hit\n",
    "            mae = high - open_price\n",
    "            mfe = open_price - low\n",
    "            return (\"Loss\", sl_price, mae, mfe)\n",
    "        else: # Neither hit, assume close price is exit\n",
    "            mae = high - open_price\n",
    "            mfe = open_price - low\n",
    "            return (None, None, mae, mfe)\n",
    "\n",
    "\n",
    "# ======== PREPARE DATA ========\n",
    "processed_data_frames = []\n",
    "print(\"Calculating technical indicators (EMA, ATR, Rolling Averages)...\")\n",
    "# Group data by Pair and Timeframe before processing for efficiency and correctness\n",
    "grouped_data = data.groupby(['Pair', 'Timeframe'])\n",
    "\n",
    "for (pair, tf), df in tqdm(grouped_data, desc=\"Processing Pairs and Timeframes\"):\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    # Ensure data is sorted by DateTime before indicator calculation\n",
    "    df = df.sort_values('DateTime').reset_index(drop=True)\n",
    "\n",
    "    df['EMA'] = df['Close'].ewm(span=ema_period, adjust=False).mean()\n",
    "    df = calculate_atr(df, atr_period)\n",
    "    df['CandleSize'] = df['Close'] - df['Open']\n",
    "    df['Rolling_Avg_CandleSize'] = df['CandleSize'].abs().rolling(window=ema_period, min_periods=1).mean()\n",
    "    if 'Volume' in df.columns:\n",
    "        df['Rolling_Avg_Volume'] = df['Volume'].rolling(window=ema_period, min_periods=1).mean()\n",
    "    processed_data_frames.append(df)\n",
    "\n",
    "data_processed = pd.concat(processed_data_frames, ignore_index=True)\n",
    "data_processed.sort_values(['Pair','Timeframe','DateTime'], inplace=True)\n",
    "data_processed.reset_index(drop=True, inplace=True)\n",
    "print(\"Technical indicators calculated.\")\n",
    "\n",
    "# Prepare primary pair data for alignment check\n",
    "primary_data_dict = {}\n",
    "df_primary_all_tfs = data_processed[data_processed['Pair']==primary_pair].copy()\n",
    "for tf in df_primary_all_tfs['Timeframe'].unique():\n",
    "    primary_data_dict[tf] = df_primary_all_tfs[df_primary_all_tfs['Timeframe']==tf].set_index('DateTime')\n",
    "\n",
    "\n",
    "# ======== BACKTEST ========\n",
    "trades = []\n",
    "# Rebuild df_by_tf after indicator updates\n",
    "df_by_tf = { (p, tf): data_processed[(data_processed['Pair']==p) & (data_processed['Timeframe']==tf)].copy()\n",
    "             for p in data_processed['Pair'].unique() for tf in data_processed['Timeframe'].unique() }\n",
    "\n",
    "print(\"Starting backtest...\")\n",
    "trade_id_counter = 0\n",
    "\n",
    "# Calculate total iterations for a more accurate progress bar\n",
    "total_iterations = sum(len(df_by_tf[(p, tf)]) for p, tf_dict in data_processed.groupby('Pair') for tf in tf_dict['Timeframe'].unique() if (p, tf) in df_by_tf)\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Backtesting Progress\") as pbar:\n",
    "    for pair in data_processed['Pair'].unique(): # Iterate over all unique pairs in the data\n",
    "        df_pair_all_tfs = data_processed[data_processed['Pair']==pair].copy()\n",
    "        \n",
    "        for tf in df_pair_all_tfs['Timeframe'].unique():\n",
    "            df = df_by_tf.get((pair, tf))\n",
    "            if df is None or df.empty:\n",
    "                continue\n",
    "            \n",
    "            # Ensure ATR and EMA are not NaN at the start of loop for calculations\n",
    "            df_filtered = df.dropna(subset=['ATR', 'EMA']).reset_index(drop=True)\n",
    "\n",
    "            for i in range(1, len(df_filtered)):\n",
    "                pbar.update(1) # Update progress bar for each row iteration\n",
    "\n",
    "                row = df_filtered.iloc[i]\n",
    "                prev = df_filtered.iloc[i-1]\n",
    "\n",
    "                # Initialize conditions flags\n",
    "                higher_tf_condition_met = False\n",
    "                volume_condition_met = False\n",
    "                primary_pair_direction_str = None\n",
    "                primary_pair_alignment = False\n",
    "                current_higher_tf_close = np.nan\n",
    "                current_higher_tf_ema = np.nan\n",
    "\n",
    "                # Big candle check\n",
    "                if abs(prev['CandleSize']) < prev['Rolling_Avg_CandleSize'] * big_candle_factor:\n",
    "                    continue\n",
    "\n",
    "                direction = 1 if prev['CandleSize'] > 0 else -1 # 1 for Buy, -1 for Sell\n",
    "\n",
    "                # Higher timeframe check\n",
    "                higher_tf_to_check = timeframe_hierarchy.get(tf, None)\n",
    "                if higher_tf_to_check:\n",
    "                    df_higher = df_by_tf.get((pair, higher_tf_to_check))\n",
    "                    if df_higher is not None and not df_higher.empty:\n",
    "                        # Find the last candle on the higher timeframe that occurred at or before the current candle's DateTime\n",
    "                        df_higher_subset = df_higher[df_higher['DateTime'] <= row['DateTime']]\n",
    "                        if not df_higher_subset.empty:\n",
    "                            row_higher = df_higher_subset.iloc[-1]\n",
    "                            current_higher_tf_close = row_higher['Close']\n",
    "                            current_higher_tf_ema = row_higher['EMA']\n",
    "                            if (direction == 1 and current_higher_tf_close < current_higher_tf_ema) or \\\n",
    "                               (direction == -1 and current_higher_tf_close > current_higher_tf_ema):\n",
    "                                continue # Condition not met, skip trade\n",
    "                            higher_tf_condition_met = True\n",
    "                else: # If no higher timeframe to check, consider the condition met\n",
    "                    higher_tf_condition_met = True\n",
    "                \n",
    "                # Volume check\n",
    "                if 'Volume' in row.index and 'Rolling_Avg_Volume' in row.index and not pd.isna(row['Rolling_Avg_Volume']):\n",
    "                    if row['Volume'] < row['Rolling_Avg_Volume'] * volume_factor:\n",
    "                        continue # Condition not met, skip trade\n",
    "                    volume_condition_met = True\n",
    "                else: # If no volume data, consider the condition met\n",
    "                    volume_condition_met = True\n",
    "\n",
    "                # Secondary pair alignment with primary\n",
    "                if pair == secondary_pair:\n",
    "                    if tf in primary_data_dict:\n",
    "                        # Find the corresponding primary pair candle at or before current DateTime\n",
    "                        primary_row_df = primary_data_dict[tf].loc[primary_data_dict[tf].index <= row['DateTime']]\n",
    "                        if not primary_row_df.empty:\n",
    "                            primary_row = primary_row_df.iloc[-1]\n",
    "                            primary_pair_candle_size = primary_row['Close'] - primary_row['Open']\n",
    "                            primary_direction = 1 if primary_pair_candle_size > 0 else -1\n",
    "                            primary_pair_direction_str = \"Buy\" if primary_direction == 1 else \"Sell\"\n",
    "\n",
    "                            if direction != primary_direction:\n",
    "                                continue # Alignment not met, skip trade\n",
    "                            primary_pair_alignment = True\n",
    "                    else: # If no primary pair data for this timeframe, skip for secondary pair alignment\n",
    "                        continue\n",
    "                \n",
    "                # Entry, TP, SL calculation\n",
    "                entry_price = row['Open']\n",
    "                atr_at_entry = row['ATR']\n",
    "                \n",
    "                # Store actual ATR factors used (or \"Default\" if fallback applied)\n",
    "                current_tp_atr_factor = tp_atr_factor\n",
    "                current_sl_atr_factor = sl_atr_factor\n",
    "                \n",
    "                if not pd.isna(atr_at_entry):\n",
    "                    tp_price = entry_price + direction * (atr_at_entry * current_tp_atr_factor)\n",
    "                    sl_price = entry_price - direction * (atr_at_entry * current_sl_atr_factor)\n",
    "                else: # Fallback if ATR is somehow NaN (should be handled by df_filtered, but good safeguard)\n",
    "                    tp_price = entry_price + direction * 0.0004 # Example default values\n",
    "                    sl_price = entry_price - direction * 0.0002 # Example default values\n",
    "                    current_tp_atr_factor = \"Default\"\n",
    "                    current_sl_atr_factor = \"Default\"\n",
    "\n",
    "                result, exit_price, mae, mfe = check_hit(entry_price, row['High'], row['Low'], row['Close'], direction, tp_price, sl_price)\n",
    "                \n",
    "                # If TP/SL not hit within the current candle, use Close price as exit\n",
    "                duration_in_candles = 1\n",
    "                if result is None:\n",
    "                    # Determine result based on open vs. close if no TP/SL hit\n",
    "                    result = \"Win\" if direction * (row['Close'] - entry_price) > 0 else \"Loss\"\n",
    "                    exit_price = row['Close']\n",
    "                    # Recalculate MAE/MFE for the candle based on open/close if TP/SL wasn't decisive\n",
    "                    if direction == 1: # Buy\n",
    "                        mae = max(0, entry_price - row['Low'])\n",
    "                        mfe = max(0, row['High'] - entry_price)\n",
    "                    else: # Sell\n",
    "                        mae = max(0, row['High'] - entry_price)\n",
    "                        mfe = max(0, entry_price - row['Low'])\n",
    "\n",
    "                actual_profit_loss = (exit_price - entry_price) * direction\n",
    "                entry_to_close_ratio = (exit_price - entry_price) / entry_price * 100 if entry_price != 0 else 0\n",
    "\n",
    "                trade_id_counter += 1\n",
    "                trade_record = {\n",
    "                    'TradeID': trade_id_counter,\n",
    "                    'Pair': pair,\n",
    "                    'Timeframe': tf,\n",
    "                    'Direction': \"Buy\" if direction == 1 else \"Sell\",\n",
    "                    'EntryDateTime': row['DateTime'],\n",
    "                    'EntryPrice': entry_price,\n",
    "                    'CandleSize_at_Entry': prev['CandleSize'],\n",
    "                    'RollingAvgCandleSize_at_Entry': prev['Rolling_Avg_CandleSize'],\n",
    "                    'Volume_at_Entry': row['Volume'] if 'Volume' in row.index else np.nan,\n",
    "                    'RollingAvgVolume_at_Entry': row['Rolling_Avg_Volume'] if 'Rolling_Avg_Volume' in row.index else np.nan,\n",
    "                    'EMA_at_Entry': row['EMA'],\n",
    "                    'ATR_at_Entry': atr_at_entry,\n",
    "                    'ATR_TP_FactorUsed': current_tp_atr_factor,\n",
    "                    'ATR_SL_FactorUsed': current_sl_atr_factor,\n",
    "                    'TP_Price': tp_price,\n",
    "                    'SL_Price': sl_price,\n",
    "                    'ExitDateTime': row['DateTime'], # For now, exit is assumed within the same candle\n",
    "                    'ExitPrice': exit_price,\n",
    "                    'Result': result,\n",
    "                    'ActualProfitLoss': actual_profit_loss,\n",
    "                    'EntryToCloseRatio': entry_to_close_ratio,\n",
    "                    'DurationInCandles': duration_in_candles,\n",
    "                    'MaxAdverseExcursion': mae, # Absolute value\n",
    "                    'MaxFavorableExcursion': mfe, # Absolute value\n",
    "                    'HigherTimeframeToMonitor': higher_tf_to_check,\n",
    "                    'HigherTimeframeClose': current_higher_tf_close,\n",
    "                    'HigherTimeframeEMA': current_higher_tf_ema,\n",
    "                    'HigherTimeframeConditionMet': higher_tf_condition_met,\n",
    "                    'VolumeConditionMet': volume_condition_met,\n",
    "                    'PrimaryPairDirection': primary_pair_direction_str,\n",
    "                    'PrimaryPairAlignment': primary_pair_alignment,\n",
    "                    'PeakProfitDurationInCandles': np.nan, # To be calculated later\n",
    "                    'PeakProfitPrice': np.nan # To be calculated later\n",
    "                }\n",
    "                trades.append(trade_record)\n",
    "\n",
    "# ======== CALCULATE PEAK PROFIT DURATION FOR WINNING TRADES ========\n",
    "# Convert list of trade dictionaries to DataFrame for easier processing\n",
    "trades_df = pd.DataFrame(trades)\n",
    "\n",
    "# Create a temporary indexed DataFrame for data_processed for efficient lookup of subsequent candles\n",
    "data_processed_indexed = data_processed.set_index(['Pair', 'Timeframe', 'DateTime'])\n",
    "\n",
    "print(\"\\nCalculating Peak Profit Duration for winning trades...\")\n",
    "# Only iterate through winning trades\n",
    "winning_trades_indices = trades_df[trades_df['Result'] == 'Win'].index\n",
    "\n",
    "for idx in tqdm(winning_trades_indices, desc=\"Calculating Peak Profit\"):\n",
    "    trade = trades_df.loc[idx]\n",
    "    pair = trade['Pair']\n",
    "    tf = trade['Timeframe']\n",
    "    exit_dt = trade['ExitDateTime']\n",
    "    direction = 1 if trade['Direction'] == 'Buy' else -1\n",
    "    exit_price = trade['ExitPrice']\n",
    "\n",
    "    # Find subsequent candles after the trade's exit DateTime\n",
    "    sub_df_after_exit = df_by_tf.get((pair, tf))\n",
    "    if sub_df_after_exit is not None:\n",
    "        sub_df_after_exit = sub_df_after_exit[sub_df_after_exit['DateTime'] > exit_dt].sort_values('DateTime')\n",
    "\n",
    "        peak_price = exit_price\n",
    "        peak_duration = 0\n",
    "        \n",
    "        for j, subsequent_candle in sub_df_after_exit.iterrows():\n",
    "            candle_high = subsequent_candle['High']\n",
    "            candle_low = subsequent_candle['Low']\n",
    "\n",
    "            if direction == 1: # Buy trade: looking for higher highs\n",
    "                if candle_high > peak_price:\n",
    "                    peak_price = candle_high\n",
    "                    peak_duration += 1\n",
    "                else: # Price stopped moving favorably\n",
    "                    break\n",
    "            else: # Sell trade: looking for lower lows\n",
    "                if candle_low < peak_price:\n",
    "                    peak_price = candle_low\n",
    "                    peak_duration += 1\n",
    "                else: # Price stopped moving favorably\n",
    "                    break\n",
    "        \n",
    "        trades_df.loc[idx, 'PeakProfitDurationInCandles'] = peak_duration\n",
    "        trades_df.loc[idx, 'PeakProfitPrice'] = peak_price\n",
    "\n",
    "print(\"Peak Profit Duration calculation complete.\")\n",
    "\n",
    "\n",
    "# ======== SAVE RESULTS ========\n",
    "total_trades = len(trades_df)\n",
    "wins = trades_df[trades_df['Result']==\"Win\"].copy()\n",
    "losses = trades_df[trades_df['Result']==\"Loss\"].copy()\n",
    "\n",
    "print(f\"\\nTotal trades: {total_trades}\")\n",
    "print(f\"Winning trades: {len(wins)}\")\n",
    "print(f\"Losing trades: {len(losses)}\")\n",
    "\n",
    "# Save to CSV\n",
    "trades_df.to_csv(os.path.join(output_folder,\"all_trades.csv\"), index=False)\n",
    "wins.to_csv(os.path.join(output_folder,\"winning_trades.csv\"), index=False)\n",
    "losses.to_csv(os.path.join(output_folder,\"losing_trades.csv\"), index=False)\n",
    "print(f\"Results saved to {output_folder}\")\n",
    "\n",
    "print(\"\\nBacktest complete with enhanced output files!\")\n",
    "print(f\"All Trades (first 5 rows):\\n{trades_df.head()}\")\n",
    "print(f\"\\nWinning Trades (first 5 rows):\\n{wins.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c959a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
